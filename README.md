# PyRL
Environment Agnostic RL algorithm implementations using Pytorch.

-- Work in progress, not too much done yet :) --

Code is type-hinted & uses minibatches - a common downfall to public libraries

Currently 4 DQN-style algorithims implemented - see exmples.ipynb for one particular environment tested

1. *Deep Q Learning (DQN)* <sub><sup> ([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub>  
2. *DQN Experience Replay*  <sub><sup> ([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub> 
3. *DQN with Fixed targets* <sub><sup>([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub> 
4. *Double Q Learning (DDQN)* <sub><sup> ([arXiv:1509.06461v3 [cs.LG] 8 Dec 2015](https://arxiv.org/pdf/1509.06461v3.pdf)) </sup></sub>   
5. REINFORCE
6. Advantage Actor Critic

 --- UPCOMING ---
 1. A3C
2. *DQN Prioritized Replay* <sub><sup> ([Google DeepMind et al. 2016](https://arxiv.org/pdf/1511.05952v3.pdf)) </sup></sub>   
3. PPO
